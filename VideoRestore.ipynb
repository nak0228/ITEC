{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VideoRestore.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "Vkkr1Sq6t2lM"
      ],
      "mount_file_id": "1u5FKUJBq5ooLQP9c49JbPPVlHurwfIei",
      "authorship_tag": "ABX9TyNIE0Lw+FBn5WTSD5j5x/KX",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nak650228/ITEC/blob/20211010/VideoRestore.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vkkr1Sq6t2lM"
      },
      "source": [
        "#◢ Video Restoration Prework\n",
        "\n",
        "プリワークでは、Youtubeまたはファイル指定により動画ファイルをダウンロードした後、DeepLearningによる補正を行う前処理を行います。\n",
        "その他にも以下の修正を施します。\n",
        "  \n",
        "・フレームのスタビライズ（手振れ補正）  \n",
        "・アップスケール/ダウンスケール（1080pに）  \n",
        "・ヒストグラムの調整  \n",
        "・シーンの分割（トランジションを判断して、複数の動画ファイルに分割します。  \n",
        "  \n",
        "出力結果は1080pの動画として、ユーザのGoogle Drive上のフォルダに作られます。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O1RKQX4WfXdg"
      },
      "source": [
        "#◢ 初期設定"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7odvNQ3P0KAt",
        "outputId": "0b0d6db4-010c-4129-aa50-6ddb8287e752"
      },
      "source": [
        "#@title 割り当てられたGPUの確認\n",
        "# Check your current GPU\n",
        "# If you are lucky, you get 16GB VRAM. If you are not lucky, you get less. VRAM is important. The more VRAM, the higher the maximum resolution will go.\n",
        "\n",
        "# 16GB: Can handle 720p. 1080p will procude an out-of-memory error. \n",
        "# 8GB: Can handle 480p. 720p will produce an out-of-memory error.\n",
        "\n",
        "!nvidia-smi --query-gpu=gpu_name,driver_version,memory.total --format=csv"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "name, driver_version, memory.total [MiB]\n",
            "Tesla P100-PCIE-16GB, 460.32.03, 16280 MiB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJ1FPSlRyxXg"
      },
      "source": [
        "#@title ライブラリ等のインストール\n",
        "%cd /content\n",
        "!pip install youtube_dl\n",
        "!pip install ffmpeg\n",
        "!pip install ffmpeg-python\n",
        "#!pip install torchvision==0.5\n",
        "!pip install torchvision\n",
        "#!pip install torch==1.4\n",
        "!pip install torch==1.9.0\n",
        "#!pip install scipy==1.2.0\n",
        "!pip install scipy\n",
        "#!pip install imgaug==0.2.5\n",
        "!pip install imgaug\n",
        "#!pip install tensorflow==1.15.5\n",
        "!pip install tensorflow\n",
        "\n",
        "#シーン分割\n",
        "!pip install scenedetect[opencv,progress_bar]\n",
        "\n",
        "!pip install subprocess\n",
        "\n",
        "import tensorflow as tf\n",
        "import youtube_dl\n",
        "import ffmpeg\n",
        "import numpy as np\n",
        "import imageio\n",
        "import cv2\n",
        "import torch\n",
        "import glob\n",
        "import shutil\n",
        "import moviepy.editor as mpy\n",
        "import os\n",
        "from IPython.display import clear_output\n",
        "torch.backends.cudnn.benchmark=True\n",
        "\n",
        "clear_output()\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "glujFIX6lE_r",
        "cellView": "form"
      },
      "source": [
        "#@title 超解像度用ライブラリのインストール（realESRGAN,BSRGAN,SwinIR)\n",
        "\n",
        "SRGAN_DIR = \"/content/Real-ESRGAN\"\n",
        "if (not os.path.isdir(SRGAN_DIR)):\n",
        "  # Clone realESRGAN\n",
        "  !git clone https://github.com/xinntao/Real-ESRGAN.git\n",
        "  %cd Real-ESRGAN\n",
        "  # Set up the environment\n",
        "  !pip install basicsr\n",
        "  !pip install facexlib\n",
        "  !pip install gfpgan\n",
        "  !pip install -r requirements.txt\n",
        "  !python setup.py develop\n",
        "\n",
        "  # Clone BSRGAN\n",
        "  !git clone https://github.com/cszn/BSRGAN.git\n",
        "\n",
        "  # Clone SwinIR\n",
        "  !git clone https://github.com/JingyunLiang/SwinIR.git\n",
        "  !pip install timm\n",
        "\n",
        "  # Download the pre-trained models\n",
        "  !wget https://github.com/cszn/KAIR/releases/download/v1.0/BSRGAN.pth -P BSRGAN/model_zoo\n",
        "  !wget https://github.com/xinntao/Real-ESRGAN/releases/download/v0.1.0/RealESRGAN_x4plus.pth -P experiments/pretrained_models\n",
        "  !wget https://github.com/JingyunLiang/SwinIR/releases/download/v0.0/003_realSR_BSRGAN_DFO_s64w8_SwinIR-M_x4_GAN.pth -P experiments/pretrained_models\n",
        "\n",
        "clear_output()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "PGULHGDLdRtR"
      },
      "source": [
        "#@title 手振れ補正用ライブラリ（SIUN)のインストール\n",
        "\n",
        "%cd /content\n",
        "\n",
        "SIUN_DIR = \"/content/SIUN\"\n",
        "\n",
        "if (not os.path.isdir(SIUN_DIR)):\n",
        "  !git clone https://github.com/minyuanye/SIUN.git\n",
        "\n",
        "  %cd /content/SIUN/code\n",
        "  !pip install h5py==2.7.1\n",
        "  !pip install tensorflow-gpu=1.15.0\n",
        "  !pip install Keras==2.2.4\n",
        "  !pip install scikit-image==0.14.3\n",
        "\n",
        "clear_output()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "y7HQUjZdjuL-"
      },
      "source": [
        "#@title 手振れ補正用ライブラリの（vidstab)のインストール\n",
        "\n",
        "!pip install vidstab[cv2]\n",
        "\n",
        "clear_output()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFRTm0VX24XD",
        "cellView": "form"
      },
      "source": [
        "#@title Microsoft Bringing-Old-Photos-Back-to-Lifeのリポジトリーをクローンする\n",
        "%cd /content\n",
        "!git clone https://github.com/microsoft/Bringing-Old-Photos-Back-to-Life.git photo_restoration\n",
        "\n",
        "clear_output()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tHeEUq563BHe",
        "cellView": "form"
      },
      "source": [
        "#@title Microsoft Bringing Old-Photos-Back-to-Lifeの学習済みモデルをダウンロード\n",
        "# pull the syncBN repo\n",
        "%cd photo_restoration/Face_Enhancement/models/networks\n",
        "!git clone https://github.com/vacancy/Synchronized-BatchNorm-PyTorch\n",
        "!cp -rf Synchronized-BatchNorm-PyTorch/sync_batchnorm .\n",
        "%cd ../../../\n",
        "\n",
        "%cd Global/detection_models\n",
        "!git clone https://github.com/vacancy/Synchronized-BatchNorm-PyTorch\n",
        "!cp -rf Synchronized-BatchNorm-PyTorch/sync_batchnorm .\n",
        "%cd ../../\n",
        "\n",
        "# download the landmark detection model\n",
        "%cd Face_Detection/\n",
        "!wget http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2\n",
        "!bzip2 -d shape_predictor_68_face_landmarks.dat.bz2\n",
        "%cd ../\n",
        "\n",
        "# download the pretrained model\n",
        "%cd Face_Enhancement/\n",
        "!wget https://facevc.blob.core.windows.net/zhanbo/old_photo/pretrain/Face_Enhancement/checkpoints.zip\n",
        "!unzip -o checkpoints.zip\n",
        "%cd ../\n",
        "\n",
        "%cd Global/\n",
        "!wget https://facevc.blob.core.windows.net/zhanbo/old_photo/pretrain/Global/checkpoints.zip\n",
        "!unzip -o checkpoints.zip\n",
        "%cd ../\n",
        "\n",
        "! pip install -r requirements.txt\n",
        "\n",
        "clear_output()"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4YQLHR6xZleu",
        "cellView": "form"
      },
      "source": [
        "#@title DeOldifyの初期設定\n",
        "%cd /content\n",
        "\n",
        "!git clone https://github.com/jantic/DeOldify.git DeOldify\n",
        "%cd DeOldify\n",
        "\n",
        "#NOTE:  This must be the first call in order to work properly!\n",
        "from deoldify import device\n",
        "from deoldify.device_id import DeviceId\n",
        "#choices:  CPU, GPU0...GPU7\n",
        "device.set(device=DeviceId.GPU0)\n",
        "\n",
        "import torch\n",
        "\n",
        "if not torch.cuda.is_available():\n",
        "    print('GPU not available.')\n",
        "\n",
        "from os import path\n",
        "\n",
        "!pip install -r colab_requirements.txt\n",
        "\n",
        "import fastai\n",
        "from deoldify.visualize import *\n",
        "from pathlib import Path\n",
        "torch.backends.cudnn.benchmark=True\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning, message=\".*?Your .*? set is empty.*?\")\n",
        "\n",
        "!mkdir 'models'\n",
        "!wget https://data.deepai.org/deoldify/ColorizeVideo_gen.pth -O ./models/ColorizeVideo_gen.pth\n",
        "\n",
        "colorizer = get_video_colorizer()\n",
        "\n",
        "clear_output()"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZwH2ifWEYEfJ",
        "cellView": "form"
      },
      "source": [
        "#@title ##**GFPGANをGithubからクローン**\n",
        "\n",
        "# Clone GFPGAN and enter the GFPGAN folder\n",
        "%cd /content\n",
        "!rm -rf GFPGAN\n",
        "!git clone https://github.com/TencentARC/GFPGAN.git\n",
        "%cd GFPGAN\n",
        "\n",
        "# Set up the environment\n",
        "# Install basicsr - https://github.com/xinntao/BasicSR\n",
        "# We use BasicSR for both training and inference\n",
        "!pip install basicsr\n",
        "# Install facexlib - https://github.com/xinntao/facexlib\n",
        "# We use face detection and face restoration helper in the facexlib package\n",
        "!pip install facexlib\n",
        "# Install other depencencies\n",
        "!pip install -r requirements.txt\n",
        "!python setup.py develop\n",
        "!pip install realesrgan  # used for enhancing the background (non-face) regions\n",
        "# Download the pre-trained model\n",
        "!wget https://github.com/TencentARC/GFPGAN/releases/download/v0.2.0/GFPGANCleanv1-NoCE-C2.pth -P experiments/pretrained_models\n",
        "clear_output()"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DqIbGxA_60Oo"
      },
      "source": [
        "#@title ##**Clone the repository of DeepRemaster** { display-mode: \"form\" }\n",
        "%cd /content\n",
        "!git clone https://github.com/satoshiiizuka/siggraphasia2019_remastering.git DeepRemaster\n",
        "!cp -r /content/video.mp4 /content/DeepRemaster/\n",
        "%cd /content/DeepRemaster\n",
        "\n",
        "!wget --continue -O model/remasternet.pth.tar -- http://iizuka.cs.tsukuba.ac.jp/data/remasternet.pth.tar\n",
        "clear_output()"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vc25QNoZbviM"
      },
      "source": [
        "#◢ 関数定義"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I2-LWRT7eo42"
      },
      "source": [
        "#@title ##**ビデオを静止画フレームに分解する** { display-mode: \"form\" }\n",
        "\n",
        "frame_folder  = \"/content/Real-ESRGAN/BSRGAN/testsets/RealSRSet\"\n",
        "\n",
        "if os.path.isdir(frame_folder):\n",
        "    shutil.rmtree(frame_folder)\n",
        "\n",
        "os.mkdir(frame_folder)\n",
        "\n",
        "os.chdir(frame_folder)\n",
        "\n",
        "!ffmpeg -i /content/video.mp4 %09d.png\n",
        "\n",
        "clear_output()"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pL23bEM24R4l"
      },
      "source": [
        "#◢ 画像のダウンロード"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-pMiFqHO0hpA",
        "cellView": "form",
        "outputId": "d9cf4248-e7aa-4901-9e86-02544b100c9f"
      },
      "source": [
        "#@title **Googleドライブの追加**\n",
        "# Connect Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "print('Google Drive connected.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Google Drive connected.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eaANNxvjMLUZ",
        "outputId": "83d657ac-a231-4613-aed9-fc607814abe5"
      },
      "source": [
        "#@title ##**ビデオのダウンロード** { display-mode: \"form\" }\n",
        "#@markdown *ビデオへのリンク（YouTubeやTwitterなど）を入力するか、source_urlフィールドを空白にしてください（空白にした場合、コンピューターからビデオをアップロードするよう求められます）。*\n",
        "#@markdown *プロジェクト名は任意でOKです。一応最後にGoogle Driveにプロジェクト名で指定したディレクトリが作られて、途中経過も含めて全ての動画ファイルがコピーされます*\n",
        "\n",
        "import youtube_dl\n",
        "import cv2\n",
        "from IPython.display import clear_output\n",
        "\n",
        "%cd /content\n",
        "\n",
        "projectname = 'Downtown18' #@param {type:\"string\"}\n",
        "\n",
        "source_url = 'https://www.youtube.com/watch?v=jenWdylTtzs' #@param {type:\"string\"}\n",
        "\n",
        "%cd /content\n",
        "! rm -f /content/*.mp4\n",
        "\n",
        "if source_url == '':\n",
        "  uploaded = files.upload()\n",
        "  for fn in uploaded.keys():\n",
        "    print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "        name=fn, length=len(uploaded[fn])))\n",
        "  os.rename(fn, fn.replace(\" \", \"\"))\n",
        "  fn = fn.replace(\" \", \"\")\n",
        "  file_name = \"downloaded_video.\" + fn.split(\".\")[-1]\n",
        "  !mv -f $fn $file_name\n",
        "\n",
        "else:\n",
        "  try:\n",
        "    ydl_opts = {\n",
        "        'format': 'bestvideo[ext=mp4]+bestaudio[ext=m4a]/mp4',\n",
        "        'outtmpl': 'downloaded_video.mp4',\n",
        "        }\n",
        "    with youtube_dl.YoutubeDL(ydl_opts) as ydl:\n",
        "      ydl.download([source_url])\n",
        "    file_name = 'downloaded_video.mp4'\n",
        "  \n",
        "  except BaseException:\n",
        "    !wget $source_url\n",
        "    fn = source_url.split('/')[-1]\n",
        "    os.rename(fn, fn.replace(\" \", \"\"))\n",
        "    fn = fn.replace(\" \", \"\")\n",
        "    file_name = \"downloaded_video.\" + fn.split(\".\")[-1]\n",
        "    !mv -f $fn $file_name\n",
        "\n",
        "!cp -r /content/downloaded_video.mp4 /content/video.mp4\n",
        "\n",
        "clear_output()\n",
        "\n",
        "fps_of_video = int(cv2.VideoCapture(file_name).get(cv2.CAP_PROP_FPS))\n",
        "frames_of_video = int(cv2.VideoCapture(file_name).get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "width_of_video = int(cv2.VideoCapture(file_name).get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "height_of_video = int(cv2.VideoCapture(file_name).get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "print (\"FPS of VIDEO: \",fps_of_video)\n",
        "print (\"Frames of VIDEO: \",frames_of_video)\n",
        "print (\"Width of VIDEO: \",width_of_video)\n",
        "print (\"Height of VIDEO: \",height_of_video)\n",
        "\n"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FPS of VIDEO:  29\n",
            "Frames of VIDEO:  2080\n",
            "Width of VIDEO:  720\n",
            "Height of VIDEO:  480\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04nmb31hVZ44"
      },
      "source": [
        "#@title ##**ダウンロードした動画を表示** { display-mode: \"form\" }\n",
        "#@markdown *ビデオは横640ドットに拡大/縮小されて表示されます*\n",
        "import moviepy.editor as mpy\n",
        "\n",
        "what_next = 'play' #@param [\"play\", \"download\"]\n",
        "if what_next == \"play\":\n",
        "  display(mpy.ipython_display(\"/content/downloaded_video.mp4\", autoplay=1, maxduration=6000,width=640))\n",
        "else:\n",
        "  files.download('/content/downloaded_video.mp4')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ObdmOuzz13m"
      },
      "source": [
        "#@markdown *1分以上の動画をダウンロードすることはお勧めできません。また、タイトルに「スペース」や「ドット」が含まれている動画はアップロードしないでください。*\n",
        "\n",
        "#@markdown *実行中にエラーが発生した場合は、このブロックを再度実行します。*\n",
        "\n",
        "#@title ##**動画の調整** { display-mode: \"form\" }\n",
        "#@markdown *動画の長さを変更することができます。*\n",
        "\n",
        "#@markdown **動画の長さを変更する場合は、その開始時間と終了時間を指定して下さい。**\n",
        "target_start = '00:00:00' #@param {type:\"string\"}\n",
        "target_end = '00:01:00' #@param {type:\"string\"}\n",
        "\n",
        "\n",
        "if os.path.isfile(\"/content/cropped_video.mp4\"):\n",
        "    os.remove(\"/content/cropped_video.mp4\")\n",
        "\n",
        "!ffmpeg -i /content/downloaded_video.mp4  -ss $target_start -to $target_end /content/cropped_video.mp4\n",
        "\n",
        "if os.path.isfile(\"/content/video.mp4\"):\n",
        "    os.remove(\"/content/video.mp4\")\n",
        "\n",
        "!cp /content/cropped_video.mp4 /content/video.mp4\n",
        "\n",
        "#@markdown **モノクロ動画にAIで色を付ける場合は有効にしてください。**\n",
        "is_deoldify = True #@param {type:\"boolean\"}\n",
        "\n",
        "\n",
        "#@markdown **Deoldifyのレンダリングファクターを指定します。(お勧めは10～25）**\n",
        "render_factor = 13  #@param {type: \"slider\", min: 5, max: 44}\n",
        "\n",
        "\n",
        "#@markdown **ヒストグラムの平均化を行う場合、動画の種類に合わせてモノクロかカラーを選択してください。**\n",
        "#@markdown **ヒストグラムの平均化を行わない場合はNoneを選択してください。**\n",
        "#@markdown **ただしこれまでの経験では有効にしてもあまりきれいにはなりませんでした**\n",
        "HistgramType = 'None' #@param [\"None\", \"Monochrome\", \"Color\"] {allow-input: true}\n",
        "\n",
        "\n",
        "#@markdown **DeepRemasterを有効にすると、低画質の動画からノイズなどを除去できます。**\n",
        "is_DeepRemaster = True #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown **GANを使って、動画の顔部分を書き換えます。大体はがっかりしますが、時々きれいに修正されることがあります**\n",
        "\n",
        "#@markdown **Microsoft Bringing-Old-Photos-Back-to-LifeまたはGFPGANを選択して、いずれかの手法で人物の精彩化を試みます。**\n",
        "which_FaceGAN = 'Microsoft' #@param [\"None\", \"GFPGAN\", \"Microsoft\"] {allow-input: true}\n",
        "\n",
        "clear_output()"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IqUFrU1vMiXw"
      },
      "source": [
        "#@title ##**サイズ調整後の動画を表示（修復対象）** { display-mode: \"form\" }\n",
        "\n",
        "what_next = 'play' #@param [\"play\", \"download\"]\n",
        "if what_next == \"play\":\n",
        "#  display(mpy.ipython_display(\"/content/video.mp4\", height=400, autoplay=1, maxduration=600))\n",
        "  display(mpy.ipython_display(\"/content/video.mp4\", autoplay=1, maxduration=600))\n",
        "else:\n",
        "  files.download('/content/video.mp4')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TXnweFAqiLuF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XT73opxp0u5H",
        "outputId": "53123750-c89b-457e-f468-45d40b22ee7b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!scenedetect --input /content/video.mp4 detect-content list-scenes save-images"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[PySceneDetect] PySceneDetect v0.5.6.1\n",
            "[PySceneDetect] Loaded 1 video, framerate: 29.970 FPS, resolution: 720 x 480\n",
            "[PySceneDetect] Downscale factor set to 3, effective resolution: 240 x 160\n",
            "[PySceneDetect] Scene list CSV file name format:\n",
            "  $VIDEO_NAME-Scenes.csv\n",
            "[PySceneDetect] Image output format set: JPEG [Quality: 95]\n",
            "[PySceneDetect] Detecting scenes...\n",
            "100% 1799/1799 [00:04<00:00, 445.75frames/s]\n",
            "[PySceneDetect] Processed 1799 frames in 4.0 seconds (average 445.09 FPS).\n",
            "[PySceneDetect] Detected 11 scenes, average shot length 5.5 seconds.\n",
            "[PySceneDetect] Writing scene list to CSV file:\n",
            "  video-Scenes.csv\n",
            "[PySceneDetect] Scene List:\n",
            "-----------------------------------------------------------------------\n",
            " | Scene # | Start Frame |  Start Time  |  End Frame  |   End Time   |\n",
            "-----------------------------------------------------------------------\n",
            " |      1  |           0 | 00:00:00.000 |         108 | 00:00:03.604 |\n",
            " |      2  |         108 | 00:00:03.604 |         191 | 00:00:06.373 |\n",
            " |      3  |         191 | 00:00:06.373 |         400 | 00:00:13.347 |\n",
            " |      4  |         400 | 00:00:13.347 |         531 | 00:00:17.718 |\n",
            " |      5  |         531 | 00:00:17.718 |         848 | 00:00:28.295 |\n",
            " |      6  |         848 | 00:00:28.295 |         916 | 00:00:30.564 |\n",
            " |      7  |         916 | 00:00:30.564 |         971 | 00:00:32.399 |\n",
            " |      8  |         971 | 00:00:32.399 |        1008 | 00:00:33.634 |\n",
            " |      9  |        1008 | 00:00:33.634 |        1521 | 00:00:50.751 |\n",
            " |     10  |        1521 | 00:00:50.751 |        1657 | 00:00:55.289 |\n",
            " |     11  |        1657 | 00:00:55.289 |        1799 | 00:01:00.027 |\n",
            "-----------------------------------------------------------------------\n",
            "\n",
            "[PySceneDetect] Comma-separated timecode list:\n",
            "  00:00:03.604,00:00:06.373,00:00:13.347,00:00:17.718,00:00:28.295,00:00:30.564,00:00:32.399,00:00:33.634,00:00:50.751,00:00:55.289\n",
            "[PySceneDetect] Downscale factor set to 1, effective resolution: 720 x 480\n",
            "[PySceneDetect] Generating output images (3 per scene)...\n",
            "100% 33/33 [00:03<00:00,  8.91images/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JZbh53bZiMEW"
      },
      "source": [
        "# #◢ 小さな動画を1080Pに拡大\n",
        "ここではSwinIRという超高解像度の手法を使っていますが。これは基本的に静止画用です。今後TecoGANもしくはiseebetterに置き換える予定です。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XbaGXBdtOrx7"
      },
      "source": [
        "#@title ##**動画のスケーリング** { display-mode: \"form\" }\n",
        "##@markdown *動画の解像度を変更することができます。*\n",
        "\n",
        "##@markdown **動画の解像度を変更する場合は、新しい解像度を指定してください（例 640 x 480）。この値を指定しない場合は、元の解像度がそのまま使われます。**\n",
        "\n",
        "if height_of_video  < 1080:\n",
        "  scale_factor = 4\n",
        "\n",
        "#width =  720#@param {type:\"number\"}\n",
        "#height =  480#@param {type:\"number\"}\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dW4qGcffQ-9V"
      },
      "source": [
        "#@title ##**ビデオを静止画フレームに分解する** { display-mode: \"form\" }\n",
        "\n",
        "frame_folder  = \"/content/Real-ESRGAN/BSRGAN/testsets/RealSRSet\"\n",
        "\n",
        "if os.path.isdir(frame_folder):\n",
        "    shutil.rmtree(frame_folder)\n",
        "\n",
        "os.mkdir(frame_folder)\n",
        "\n",
        "os.chdir(frame_folder)\n",
        "\n",
        "!ffmpeg -i /content/video.mp4 %09d.png\n",
        "\n",
        "clear_output()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MPcOhi21RGk-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "outputId": "5eff4098-54e5-45ae-bd86-7c9524157ab4"
      },
      "source": [
        "#@title ##**SwinIRによる動画の拡大** { display-mode: \"form\" }\n",
        "\n",
        "os.chdir(\"/content/Real-ESRGAN\")\n",
        "upscale_command=\"python SwinIR/main_test_swinir.py --task real_sr --model_path experiments/pretrained_models/003_realSR_BSRGAN_DFO_s64w8_SwinIR-M_x4_GAN.pth --folder_lq BSRGAN/testsets/RealSRSet --scale \" + str(scale_factor)\n",
        "subprocess.run(upscale_command,shell=True)\n",
        "\n",
        "#!python SwinIR/main_test_swinir.py --task real_sr --model_path experiments/pretrained_models/003_realSR_BSRGAN_DFO_s64w8_SwinIR-M_x4_GAN.pth --folder_lq BSRGAN/testsets/RealSRSet --scale \n",
        "shutil.move('results/swinir_real_sr_x4', 'results/SwinIR')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/lib/python3.7/shutil.py\u001b[0m in \u001b[0;36mmove\u001b[0;34m(src, dst, copy_function)\u001b[0m\n\u001b[1;32m    565\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 566\u001b[0;31m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_dst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    567\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'results/swinir_real_sr_x2' -> 'results/SwinIR'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-2e7639b72569>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#!python SwinIR/main_test_swinir.py --task real_sr --model_path experiments/pretrained_models/003_realSR_BSRGAN_DFO_s64w8_SwinIR-M_x4_GAN.pth --folder_lq BSRGAN/testsets/RealSRSet --scale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'results/swinir_real_sr_x2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'results/SwinIR'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/lib/python3.7/shutil.py\u001b[0m in \u001b[0;36mmove\u001b[0;34m(src, dst, copy_function)\u001b[0m\n\u001b[1;32m    578\u001b[0m             \u001b[0mrmtree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m             \u001b[0mcopy_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_dst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munlink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mreal_dst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/shutil.py\u001b[0m in \u001b[0;36mcopy2\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0mdst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m     \u001b[0mcopyfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m     \u001b[0mcopystat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/shutil.py\u001b[0m in \u001b[0;36mcopyfile\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msymlink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfsrc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfdst\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m                 \u001b[0mcopyfileobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfsrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'results/swinir_real_sr_x2'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQXyLbS2SKjE"
      },
      "source": [
        "#@title ##**修復した静止画を動画に復元** { display-mode: \"form\" }\n",
        "#!ffmpeg -vsync 0 -hwaccel cuvid -c:v mjpeg_cuvid -framerate 30 -i /content/TecoGAN/results/My_video/*.png -c:v h264_nvenc quaid2.mp4\n",
        "\n",
        "upscaled_file=\"/content/upscaled_video.mp4\"\n",
        "result_folder=\"/content/Real-ESRGAN/results/SwinIR/\"\n",
        "\n",
        "if os.path.isfile(upscaled_file) :\n",
        "    os.remove(upscaled_file)\n",
        "\n",
        "os.chdir(result_folder)\n",
        "\n",
        "subprocess.run('/usr/bin/ffmpeg -f image2 -framerate ' + str(fps_of_video) + ' -i /content/Real-ESRGAN/results/SwinIR/%09d_SwinIR.png -c:v h264_nvenc -preset slow -qp 18 -pix_fmt yuv420p /content/upscaled_video.mp4' , shell=True )\n",
        "#!ffmpeg -f image2 -framerate fps_of_video -i %09d.png -c:v h264_nvenc -preset slow -qp 18 -pix_fmt yuv420p /content/histgram_video.mp4\n",
        "#!rm -f /content/histgram_video.mp4\n",
        "!cp /content/upscaled_video.mp4 /content/video.mp4\n",
        "\n",
        "#clear_output()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qnXIazhtTJId"
      },
      "source": [
        "#@title ##**拡大した動画を1080pに変換** { display-mode: \"form\" }\n",
        "\n",
        "width = int(width_of_video *  1080 / height_of_video)\n",
        "height = 1080\n",
        "\n",
        "rescale = \"\"\n",
        "if width != '' and height != '':\n",
        "  rescale = f\"-s {width}x{height}\"\n",
        "  rescale = f\"-vf scale={width}:{height}\"\n",
        "\n",
        "!ffmpeg -i /content/upscaled_video.mp4 $rescale /content/resized_video.mp4\n",
        "\n",
        "if os.path.isfile(\"/content/video.mp4\"):\n",
        "    os.remove(\"/content/video.mp4\")\n",
        "\n",
        "!cp /content/resized_video.mp4 /content/video.mp4\n",
        "\n",
        "clear_output()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-f1MDliBGGGL"
      },
      "source": [
        "# #◢ モノクロ動画に色を付ける"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37yAH_olbROZ",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "89a65c8b-8716-40be-af0a-c0579ca4fb12"
      },
      "source": [
        "#@title Deoldifyによるモノクロ動画のカラー化\n",
        "if is_deoldify == True:\n",
        "\n",
        "  %cd /content/DeOldify\n",
        "\n",
        "  if os.path.isfile(\"/content/DeOldify/video\"):\n",
        "    shutil.rmtree(\"/content/DeOldify/video\")\n",
        "\n",
        "  !mkdir -p '/content/DeOldify/video/source'\n",
        "\n",
        "  !cp -r /content/video.mp4 /content/DeOldify/video/source/video.mp4\n",
        "  video_path = colorizer.colorize_from_file_name('/content/DeOldify/video/source/video.mp4', render_factor)\n",
        "  !cp -r /content/DeOldify/video/result/video.mp4 /content/colorized_video.mp4\n",
        "  !cp -r /content/colorized_video.mp4 /content/video.mp4\n",
        "  if os.path.isfile(\"/content/DeOldify/video/result/video.mp4\"):\n",
        "    os.remove(\"/content/DeOldify/video/result/video.mp4\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/DeOldify\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='720' class='' max='720' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      100.00% [720/720 01:10<00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Video created here: video/result/video.mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yOmvpYPnwwi6"
      },
      "source": [
        "#@title ##**カラー化後の表示** { display-mode: \"form\" }\n",
        "\n",
        "what_next = 'play' #@param [\"play\", \"download\"]\n",
        "if what_next == \"play\":\n",
        "  display(mpy.ipython_display(\"/content/colorized_video.mp4\", autoplay=1, maxduration=600))\n",
        "else:\n",
        "  files.download('/content/colorlized_video.mp4')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FakQk0wBE5GS"
      },
      "source": [
        "# #◢ ノイズ除去(Deep Remaster)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xzu_lk9DKbTO",
        "outputId": "5290aa24-ce00-4f30-ebb6-af1e6d5a2189"
      },
      "source": [
        "#@title ##**Remove frame noise** { display-mode: \"form\" }\n",
        "%cd /content/DeepRemaster\n",
        "command = \"python remaster.py --input /content/video.mp4 --disable_colorization --gpu --mindim \"+str(height)\n",
        "\n",
        "#subprocess.run(command,shell=True)\n",
        "!python remaster.py --input /content/video.mp4 --disable_colorization --gpu --mindim 1080\n",
        "#!python remaster.py --input /content/video.mp4 --disable_colorization --gpu\n",
        "#clear_output()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/DeepRemaster\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CompletedProcess(args='python remaster.py --input /content/video.mp4 --disable_colorization --gpu --mindim 1080', returncode=0)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J57qoHNdpyjf"
      },
      "source": [
        "#@title ##**ノイズ除去結果の表示** { display-mode: \"form\" }\n",
        "!rm -rf /content/video.mp4\n",
        "!cp -r video_out.mp4 /content/video.mp4\n",
        "!cp -r video_out.mp4 /content/denoise_video.mp4\n",
        "what_next = 'play' #@param [\"play\", \"download\"]\n",
        "if what_next == \"play\":\n",
        "  display(mpy.ipython_display(\"/content/denoise_video.mp4\", autoplay=1, maxduration=600))\n",
        "else:\n",
        "  files.download('/content/denoise_video.mp4')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLW6PDpoXeZr"
      },
      "source": [
        "#◢ 画像の修復(ヒストグラムの修正）"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EeY4HJIa9-Si"
      },
      "source": [
        "#@title ##**ビデオを静止画フレームに分解する** { display-mode: \"form\" }\n",
        "\n",
        "if HistgramType != \"None\":\n",
        "  upload_folder = \"/content/datas\"\n",
        "  frame_folder  = \"/content/datas/frames\"\n",
        "\n",
        "  if os.path.isdir(upload_folder):\n",
        "    shutil.rmtree(upload_folder)\n",
        "\n",
        "  os.mkdir(upload_folder)\n",
        "  os.mkdir(frame_folder)\n",
        "\n",
        "  os.chdir(frame_folder)\n",
        "\n",
        "  !ffmpeg -i /content/video.mp4 %09d.png\n",
        "\n",
        "  clear_output()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TADaeUAG8QIp"
      },
      "source": [
        "#@title ##**白黒画像のヒストグラムを平坦化する** { display-mode: \"form\" }\n",
        "\n",
        "if is_Histgram == \"Monochrome\":\n",
        "  files = os.listdir(frame_folder)\n",
        "\n",
        "  for file in files:\n",
        "    img = cv2.imread(file,0)\n",
        "\n",
        "  # create a CLAHE object (Arguments are optional).\n",
        "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
        "    cl1 = clahe.apply(img)\n",
        "\n",
        "    cv2.imwrite(file,cl1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5rjIeF-FUnwL"
      },
      "source": [
        "#@title ##**カラー画像のヒストグラムを平坦化する** { display-mode: \"form\" }\n",
        "import cv2\n",
        "\n",
        "# ヒストグラム平坦化でコントラスト強調                                                                                                      \n",
        "def eqh(img):\n",
        "    # 各色で平坦化                                                                                                                          \n",
        "    b1,g1,r1 = cv2.split(img)\n",
        "    b2 = cv2.equalizeHist(b1)\n",
        "    g2 = cv2.equalizeHist(g1)\n",
        "    r2 = cv2.equalizeHist(r1)\n",
        "    eqh_rgb = cv2.merge((b2,g2,r2))\n",
        "\n",
        "    # HSVのvだけ編集                                                                                                                        \n",
        "    h1,s1,v1 = cv2.split(cv2.cvtColor(img,cv2.COLOR_BGR2HSV))  # 色空間をBGRからHSVに変換                                                   \n",
        "    v2 = cv2.equalizeHist(v1)\n",
        "    eqh_hsv = cv2.cvtColor(cv2.merge((h1,s1,v2)), cv2.COLOR_HSV2BGR)\n",
        "\n",
        "    return eqh_rgb, eqh_hsv\n",
        "\n",
        "# 部分的にヒストグラム平坦化でコントラスト強調                                                                                              \n",
        "def clc(img,cl,gsize):\n",
        "    b1,g1,r1 = cv2.split(img)\n",
        "    clahe = cv2.createCLAHE(clipLimit=cl, tileGridSize=(gsize,gsize))\n",
        "    b2 = clahe.apply(b1)\n",
        "    g2 = clahe.apply(g1)\n",
        "    r2 = clahe.apply(r1)\n",
        "    return cv2.merge((b2,g2,r2))\n",
        "\n",
        "# 値を0-255にclipして、typeをuint8にする                                                                                                    \n",
        "def ct(img):\n",
        "    return np.clip(img,0,255).astype(np.uint8)\n",
        "\n",
        "\n",
        "if HistgramType == \"Color\":\n",
        "  files = os.listdir(\"/content/datas/frames\")\n",
        "\n",
        "  for file in files:\n",
        "    img = cv2.imread(file)\n",
        "    # コントラスト強調画像を作成 \n",
        "    eqh_rgb,eqh_hsv = eqh(img)\n",
        "    clc_img = clc(img,2.,4)\n",
        "    # 全部混ぜる                                                                                                                                \n",
        "    ave_img = ct((np.float32(img) \\\n",
        "            + np.float32(eqh_rgb) \\\n",
        "            + np.float32(eqh_hsv) \\\n",
        "            + np.float32(clc_img))/4.)\n",
        "\n",
        "\n",
        "    cv2.imwrite(file,ave_img)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9ezC5Y3GrZZ"
      },
      "source": [
        "#@title ##**修復した静止画を動画に復元** { display-mode: \"form\" }\n",
        "#!ffmpeg -vsync 0 -hwaccel cuvid -c:v mjpeg_cuvid -framerate 30 -i /content/TecoGAN/results/My_video/*.png -c:v h264_nvenc quaid2.mp4\n",
        "\n",
        "if HistgramType != \"None\":\n",
        "  import subprocess\n",
        "  histgram_file=\"/content/histgram_video.mp4\"\n",
        "\n",
        "  if os.path.isfile(histgram_file) :\n",
        "    os.remove(histgram_file)\n",
        "\n",
        "  os.chdir(frame_folder)\n",
        "\n",
        "  subprocess.run('/usr/bin/ffmpeg -f image2 -framerate ' + str(fps_of_video) + ' -i /content/datas/frames/%09d.png -c:v h264_nvenc -preset slow -qp 18 -pix_fmt yuv420p /content/histgram_video.mp4' , shell=True )\n",
        "#!ffmpeg -f image2 -framerate fps_of_video -i %09d.png -c:v h264_nvenc -preset slow -qp 18 -pix_fmt yuv420p /content/histgram_video.mp4\n",
        "#!rm -f /content/histgram_video.mp4\n",
        "  !cp /content/histgram_video.mp4 /content/video.mp4\n",
        "\n",
        "#clear_output()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7UPY9esyurWB"
      },
      "source": [
        "#@title ##**ヒストグラム調整後の動画を表示** { display-mode: \"form\" }\n",
        "\n",
        "what_next = 'play' #@param [\"play\", \"download\"]\n",
        "if what_next == \"play\":\n",
        "#  display(mpy.ipython_display(\"/content/video.mp4\", height=400, autoplay=1, maxduration=600))\n",
        "  display(mpy.ipython_display(\"/content/video.mp4\", autoplay=1, maxduration=600))\n",
        "else:\n",
        "  files.download('/content/video.mp4')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3tKlt3_S9DgG"
      },
      "source": [
        "#◢ Microsoft Bringing-Old-Photos-Back-to-Lifeによる画像修正"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qTmlNEoU-END",
        "cellView": "form"
      },
      "source": [
        "#@title 動画ファイルを画像ファイルに分解\n",
        "# ffmpeg extract - Generating individual frame PNGs from the source file.\n",
        "\n",
        "import shutil\n",
        "if which_FaceGAN == \"Microsoft\":\n",
        "\n",
        "  %cd /content/photo_restoration\n",
        "\n",
        "  FRAME_INPUT_DIR = \"/content/photo_restoration/input_frames\"\n",
        "  FRAME_OUTPUT_DIR = \"/content/photo_restoration/output_frames\"\n",
        "  INPUT_FILEPATH = \"/content/video.mp4\"\n",
        "\n",
        "  if os.path.isfile(FRAME_INPUT_DIR):\n",
        "    shutil.retree(FRAME_INPUT_DIR)\n",
        "\n",
        "  %shell mkdir -p '{FRAME_INPUT_DIR}'\n",
        "\n",
        "  %shell ffmpeg -i '{INPUT_FILEPATH}' '{FRAME_INPUT_DIR}/%05d.png'\n",
        "\n",
        "  png_generated_count_command_result = %shell ls '{FRAME_INPUT_DIR}' | wc -l\n",
        "  from IPython.display import clear_output\n",
        "\n",
        "  pngs_generated_count = int(png_generated_count_command_result.output.strip())\n",
        "\n",
        "\n",
        "  #print(f\"Input FPS: {fps}\")\n",
        "  print(f\"{pngs_generated_count} frame PNGs generated.\")\n",
        "\n",
        "  # Checking if PNG do have alpha\n",
        "  import subprocess as sp\n",
        "  %cd {FRAME_INPUT_DIR}\n",
        "  channels = sp.getoutput('identify -format %[channels] 00001.png')\n",
        "  print (f\"{channels} detected\")\n",
        "\n",
        "  # Removing alpha if detected\n",
        "  if \"a\" in channels:\n",
        "    print(\"Alpha detected and will be removed.\")\n",
        "    print(sp.getoutput('find . -name \"*.png\" -exec convert \"{}\" -alpha off PNG24:\"{}\" \\;'))\n",
        "\n",
        "  clear_output()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uD5liw_1BaI-",
        "cellView": "form"
      },
      "source": [
        "#@title 精彩化の実行\n",
        "\n",
        "if which_FaceGAN == \"Microsoft\":\n",
        "  %cd /content/photo_restoration\n",
        "  input_folder = FRAME_INPUT_DIR\n",
        "  output_folder = FRAME_OUTPUT_DIR\n",
        "\n",
        "  !rm -rf /content/photo_restoration/output_frames/*\n",
        "\n",
        "  print (input_folder)\n",
        "  print (output_folder)\n",
        "\n",
        "  import os\n",
        "  basepath = os.getcwd()\n",
        "  #input_path = os.path.join(basepath, input_folder)\n",
        "  #output_path = os.path.join(basepath, output_folder)\n",
        "  #os.mkdir(output_path)\n",
        "  #!rm -rf output_folder\n",
        "  #os.mkdir(output_folder)\n",
        "\n",
        "  !python run.py --input_folder /content/photo_restoration/input_frames --output_folder /content/photo_restoration/output_frames --GPU 0\n",
        "\n",
        "  clear_output()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rgffZHScChcI",
        "cellView": "form"
      },
      "source": [
        "#@title ビデオファイルの作成\n",
        "#create video\n",
        "\n",
        "if which_FaceGAN == \"Microsoft\":\n",
        "  %cd /content/photo_restoration/output_frames/final_output\n",
        "  !ffmpeg  -pattern_type glob -i '*.png' -c:v h264_nvenc -pix_fmt yuv420p /content/beautified_video.mp4\n",
        "  !cp /content/output.mp4 /content/drive/MyDrive/Movie\n",
        "\n",
        "  clear_output()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aGrd5Y8nmCzD"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Gs_T5WOZByX"
      },
      "source": [
        "#@title ##**Get result** { display-mode: \"form\" }\n",
        "if which_FaceGAN == \"Microsoft\":\n",
        "  !rm -rf /content/video.mp4\n",
        "  !cp -r /content/beautified_video.mp4 /content/video.mp4\n",
        "  what_next = 'play' #@param [\"play\", \"download\"]\n",
        "  if what_next == \"play\":\n",
        "    display(mpy.ipython_display(\"/content/beautified_video.mp4\", autoplay=1,  maxduration=600))\n",
        "  else:\n",
        "    files.download('/content/beautified_video.mp4')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "smSeEdA4Mv5X"
      },
      "source": [
        "#◢ GFPGANによる顔画像の修復"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OzlCT4FRGrGt"
      },
      "source": [
        "#@title ##**ビデオを静止画フレームに分解する** { display-mode: \"form\" }\n",
        "\n",
        "if which_FaceGAN == \"GFPGAN\":\n",
        "\n",
        "  upload_folder = \"/content/GFPGAN/inputs/upload\"\n",
        "  if os.path.isdir(upload_folder):\n",
        "    shutil.rmtree(upload_folder)\n",
        "\n",
        "  os.mkdir(upload_folder)\n",
        "\n",
        "  %cd /content/GFPGAN/inputs/upload\n",
        "\n",
        "  !ffmpeg -i /content/video.mp4 %09d.png\n",
        "\n",
        "  clear_output()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmQVC3s97z4z"
      },
      "source": [
        "#@title ##**GFPGANによる修復** { display-mode: \"form\" }\n",
        "# Now we use the GFPGAN to restore the above low-quality images\n",
        "# We use [Real-ESRGAN](https://github.com/xinntao/Real-ESRGAN) for enhancing the background (non-face) regions\n",
        "if which_FaceGAN == \"GFPGAN\":\n",
        "  %cd /content/GFPGAN\n",
        "  !rm -rf results\n",
        "  !python inference_gfpgan.py --upscale 2 --test_path inputs/upload --save_root results --model_path experiments/pretrained_models/GFPGANCleanv1-NoCE-C2.pth --bg_upsampler realesrgan\n",
        "  clear_output()\n",
        "\n",
        "  !ls results/cmp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Asmkh0VyKFa7"
      },
      "source": [
        "#@title ##**修復した静止画を動画に復元** { display-mode: \"form\" }\n",
        "#!ffmpeg -vsync 0 -hwaccel cuvid -c:v mjpeg_cuvid -framerate 30 -i /content/TecoGAN/results/My_video/*.png -c:v h264_nvenc quaid2.mp4\n",
        "if which_FaceGAN == \"GFPGAN\":\n",
        "  if os.path.isfile(\"/content/restored_video.mp4\") :\n",
        "    !rm -f /content/restored_video.mp4\n",
        "\n",
        "  !ffmpeg -f image2 -framerate 30 -i /content/GFPGAN/results/restored_imgs/%09d.png -c:v h264_nvenc -preset slow -qp 18 -pix_fmt yuv420p /content/restored_video.mp4\n",
        "  !rm -f /content/video.mp4\n",
        "  !cp /content/restored_video.mp4 /content/video.mp4\n",
        "\n",
        "  clear_output()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lvR7i4CEPfg9"
      },
      "source": [
        "#@title ##**修復した動画を表示** { display-mode: \"form\" }\n",
        "#@markdown *what_nextにplayを指定すると、GFPGANで修復した結果を表示します。解像度が大きな動画は表示が失敗することがあります。その場合はwhat_nextにdownloadを指定して、PCなどにダウンロードして確認して下さい*\n",
        "\n",
        "if which_FaceGAN == \"GFPGAN\":\n",
        "  what_next = 'play' #@param [\"play\", \"download\"]\n",
        "  if what_next == \"play\":\n",
        "    #  display(mpy.ipython_display(\"/content/video.mp4\", height=400, autoplay=1, maxduration=600))\n",
        "    display(mpy.ipython_display(\"/content/video.mp4\", autoplay=1, maxduration=600,width=640))\n",
        "  else:\n",
        "    files.download('/content/video.mp4')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x1Yy74PQnWUE"
      },
      "source": [
        "#◢ 最終処理"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Cj0Kxnzi_ah",
        "outputId": "103b6b92-34a5-44fc-fdf3-e9db4232cb7f"
      },
      "source": [
        "#@title ファイルのバックアップ\n",
        "\n",
        "ProjectDir=\"/content/drive/MyDrive/Movie/\"+str(projectname)\n",
        "print(\"ProjectDir\")\n",
        "\n",
        "if os.path.isfile(ProjectDir):\n",
        "    shutil.rmtree(ProjectDir)\n",
        "\n",
        "os.mkdir(ProjectDir)\n",
        "os.chdir(ProjectDir)\n",
        "!mv /content/*.mp4 ."
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ProjectDir\n"
          ]
        }
      ]
    }
  ]
}