{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VideoRestore.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "Vkkr1Sq6t2lM"
      ],
      "mount_file_id": "1u5FKUJBq5ooLQP9c49JbPPVlHurwfIei",
      "authorship_tag": "ABX9TyOrN674wVbEYqK9mnHEa6Uo",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nak650228/ITEC/blob/20211010/VideoRestore.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vkkr1Sq6t2lM"
      },
      "source": [
        "#◢ Video Restoration Prework\n",
        "\n",
        "プリワークでは、Youtubeまたはファイル指定により動画ファイルをダウンロードし後後、DeepLearningによる補正を行う前処理を行います。\n",
        "\n",
        "その他にも以下の修正を施します。\n",
        "\n",
        "　　・DeOldifyによるモノクロ画像のカラー化\n",
        "\n",
        "　　・Deep Remasterによるノイズ等の除去\n",
        "\n",
        "　　・アンシャープマスクの適用（OpenCVによる）\n",
        "\n",
        "　　・Microsoft Bringing-Old-Photos-Back-to-LifeまたはGFPGANによる顔画像の修復  \n",
        "\n",
        "\n",
        "今後の機能追加\n",
        "\n",
        "　　・超解像度化（4Kもしくは2Kに）\n",
        "\n",
        "　 　　 ToDo TecoGANもしくはiseebetterを適用する（通常動画）\n",
        "\n",
        "　　　　　　RealESRGANまたは Waifuを適用する（アニメなど）\n",
        "\n",
        "　　・シーンの分割（トランジションを判断して、複数の動画ファイルに分割します。  \n",
        "\n",
        "　　   　ToDo  分割したシーンごとに変換を行うよう、各処理を関数化する\n",
        "\n",
        "　　・DAINを使ったフレーム補完\n",
        "\n",
        "　　・音声データの取得と変換後ビデオへの追加  \n",
        "\n",
        "　　   　ToDo  選択した動画領域から、音声データを取得、最終的結果にアペンドさせる\n",
        "\n",
        "\n",
        "  \n",
        "各処理ごとの出力結果が、ユーザのGoogle Drive上のMovieフォルダに作られます。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O1RKQX4WfXdg"
      },
      "source": [
        "#◢ 初期設定"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJ1FPSlRyxXg"
      },
      "source": [
        "#@title ライブラリ等のインストール\n",
        "%cd /content\n",
        "!pip install youtube_dl\n",
        "!pip install ffmpeg\n",
        "!pip install ffmpeg-python\n",
        "#!pip install torchvision==0.5\n",
        "!pip install torchvision\n",
        "#!pip install torch==1.4\n",
        "!pip install torch==1.9.0\n",
        "#!pip install scipy==1.2.0\n",
        "!pip install scipy\n",
        "#!pip install imgaug==0.2.5\n",
        "!pip install imgaug\n",
        "#!pip install tensorflow==1.15.5\n",
        "!pip install tensorflow\n",
        "\n",
        "#シーン分割\n",
        "!pip install scenedetect[opencv,progress_bar]\n",
        "\n",
        "!pip install subprocess\n",
        "\n",
        "import subprocess\n",
        "import tensorflow as tf\n",
        "import youtube_dl\n",
        "import ffmpeg\n",
        "import numpy as np\n",
        "import imageio\n",
        "import cv2\n",
        "import torch\n",
        "import glob\n",
        "import shutil\n",
        "import moviepy.editor as mpy\n",
        "import os\n",
        "from IPython.display import clear_output\n",
        "torch.backends.cudnn.benchmark=True\n",
        "\n",
        "clear_output()\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tHeEUq563BHe",
        "cellView": "form"
      },
      "source": [
        "#@title Microsoft Bringing-Old-Photos-Back-to-Lifeのリポジトリーをクローンする\n",
        "%cd /content\n",
        "!git clone https://github.com/microsoft/Bringing-Old-Photos-Back-to-Life.git photo_restoration\n",
        "\n",
        "#@markdown Microsoft Bringing Old-Photos-Back-to-Lifeの学習済みモデルをダウンロード\n",
        "# pull the syncBN repo\n",
        "%cd photo_restoration/Face_Enhancement/models/networks\n",
        "!git clone https://github.com/vacancy/Synchronized-BatchNorm-PyTorch\n",
        "!cp -rf Synchronized-BatchNorm-PyTorch/sync_batchnorm .\n",
        "%cd ../../../\n",
        "\n",
        "%cd Global/detection_models\n",
        "!git clone https://github.com/vacancy/Synchronized-BatchNorm-PyTorch\n",
        "!cp -rf Synchronized-BatchNorm-PyTorch/sync_batchnorm .\n",
        "%cd ../../\n",
        "\n",
        "# download the landmark detection model\n",
        "%cd Face_Detection/\n",
        "!wget http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2\n",
        "!bzip2 -d shape_predictor_68_face_landmarks.dat.bz2\n",
        "%cd ../\n",
        "\n",
        "# download the pretrained model\n",
        "%cd Face_Enhancement/\n",
        "!wget https://facevc.blob.core.windows.net/zhanbo/old_photo/pretrain/Face_Enhancement/checkpoints.zip\n",
        "!unzip -o checkpoints.zip\n",
        "%cd ../\n",
        "\n",
        "%cd Global/\n",
        "!wget https://facevc.blob.core.windows.net/zhanbo/old_photo/pretrain/Global/checkpoints.zip\n",
        "!unzip -o checkpoints.zip\n",
        "%cd ../\n",
        "\n",
        "! pip install -r requirements.txt\n",
        "\n",
        "clear_output()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4YQLHR6xZleu",
        "cellView": "form"
      },
      "source": [
        "#@title DeOldifyの初期設定\n",
        "%cd /content\n",
        "\n",
        "!git clone https://github.com/jantic/DeOldify.git DeOldify\n",
        "%cd DeOldify\n",
        "\n",
        "#NOTE:  This must be the first call in order to work properly!\n",
        "from deoldify import device\n",
        "from deoldify.device_id import DeviceId\n",
        "#choices:  CPU, GPU0...GPU7\n",
        "device.set(device=DeviceId.GPU0)\n",
        "\n",
        "import torch\n",
        "\n",
        "if not torch.cuda.is_available():\n",
        "    print('GPU not available.')\n",
        "\n",
        "from os import path\n",
        "\n",
        "!pip install -r colab_requirements.txt\n",
        "\n",
        "import fastai\n",
        "from deoldify.visualize import *\n",
        "from pathlib import Path\n",
        "torch.backends.cudnn.benchmark=True\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning, message=\".*?Your .*? set is empty.*?\")\n",
        "\n",
        "!mkdir 'models'\n",
        "!wget https://data.deepai.org/deoldify/ColorizeVideo_gen.pth -O ./models/ColorizeVideo_gen.pth\n",
        "\n",
        "colorizer = get_video_colorizer()\n",
        "\n",
        "clear_output()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZwH2ifWEYEfJ",
        "cellView": "form"
      },
      "source": [
        "#@title ##**GFPGANをGithubからクローン**\n",
        "\n",
        "# Clone GFPGAN and enter the GFPGAN folder\n",
        "%cd /content\n",
        "!rm -rf GFPGAN\n",
        "!git clone https://github.com/TencentARC/GFPGAN.git\n",
        "%cd GFPGAN\n",
        "\n",
        "# Set up the environment\n",
        "# Install basicsr - https://github.com/xinntao/BasicSR\n",
        "# We use BasicSR for both training and inference\n",
        "!pip install basicsr\n",
        "# Install facexlib - https://github.com/xinntao/facexlib\n",
        "# We use face detection and face restoration helper in the facexlib package\n",
        "!pip install facexlib\n",
        "# Install other depencencies\n",
        "!pip install -r requirements.txt\n",
        "!python setup.py develop\n",
        "!pip install realesrgan  # used for enhancing the background (non-face) regions\n",
        "# Download the pre-trained model\n",
        "!wget https://github.com/TencentARC/GFPGAN/releases/download/v0.2.0/GFPGANCleanv1-NoCE-C2.pth -P experiments/pretrained_models\n",
        "clear_output()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DqIbGxA_60Oo"
      },
      "source": [
        "#@title ##**Clone the repository of DeepRemaster** { display-mode: \"form\" }\n",
        "%cd /content\n",
        "!git clone https://github.com/satoshiiizuka/siggraphasia2019_remastering.git DeepRemaster\n",
        "!cp -r /content/video.mp4 /content/DeepRemaster/\n",
        "%cd /content/DeepRemaster\n",
        "\n",
        "!wget --continue -O model/remasternet.pth.tar -- http://iizuka.cs.tsukuba.ac.jp/data/remasternet.pth.tar\n",
        "clear_output()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vc25QNoZbviM"
      },
      "source": [
        "#◢ 関数定義"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I2-LWRT7eo42",
        "cellView": "form"
      },
      "source": [
        "#@title 各種関数の定義\n",
        "#@markdown **decomposit_video(展開先フォルダ, ソースビデオファイル)  　　　　ビデオを静止画フレームに分解する**\n",
        "#@markdown **unsharp_mask(ソースイメージ, 先鋭化の強さ)　　　　　　　　　　静止画のエッジなどを強調する**\n",
        "\n",
        "def decomposit_video(video_folder,video_file):\n",
        "  if os.path.isdir(video_folder):\n",
        "    shutil.rmtree(video_folder)\n",
        "\n",
        "  os.mkdir(video_folder)\n",
        "\n",
        "  os.chdir(video_folder)\n",
        "\n",
        "  decompose_command = 'ffmpeg -i ' + video_file + ' %09d.png'\n",
        "  subprocess.run(decompose_command, shell=True)\n",
        "  #!ffmpeg -i /content/video.mp4 %09d.png\n",
        "\n",
        "  clear_output()\n",
        "\n",
        "def composit_video(video_folder, video_file, frame_rate):\n",
        "  if os.path.isfile(video_file):\n",
        "    os.remove(video_file)\n",
        "\n",
        "  compose_command='ffmpeg -f image2 -framerate ' + str(frame_rate) + ' -i ' + video_folder + '/%09d.png -c:v h264_nvenc -preset slow -qp 18 -pix_fmt yuv420p ' + video_file\n",
        "  subprocess.run(compose_command, shell=True)\n",
        "  clear_output()\n",
        "\n",
        "def UnSharpMask(image_file, k):\n",
        "    kernel = np.array([[-k/9.0, -k/9.0, -k/9.0],\n",
        "                    [-k/9.0, 1 + (8 * k)/9.0, -k/9.0],\n",
        "                    [-k/9.0, -k/9.0, -k/9.0]])\n",
        "    dst = cv2.filter2D(image_file, -1, kernel)\n",
        "    return dst\n",
        "\n",
        "def make_sharp_kernel(k: int):\n",
        "  return np.array([\n",
        "    [-k / 9, -k / 9, -k / 9],\n",
        "    [-k / 9, 1 + 8 * k / 9, k / 9],\n",
        "    [-k / 9, -k / 9, -k / 9]\n",
        "  ], np.float32)\n",
        "\n",
        "def unsharp_mask_movie(video_folder, video_file, k, frame_rate):\n",
        "  decomposit_video(video_folder,video_file)\n",
        "\n",
        "  files = glob.glob(video_folder+'/*.png')\n",
        "  for ifile in files:\n",
        "    print(\"Now processing \",ifile)\n",
        "    imageblur = cv2.imread(ifile, 0)\n",
        "#    imagesharp = UnSharpMask(imageblur,k)\n",
        "\n",
        "    kernel=make_sharp_kernel(1.0)\n",
        "    imagesharp=cv2.filter2D(imageblur,-1,kernel).astype(\"uint8\")\n",
        "    cv2.imwrite(ifile, imagesharp)\n",
        "\n",
        "  composit_video(video_folder, video_file, frame_rate)\n",
        "\n",
        "\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "\n",
        "def load_tensor(image_file):\n",
        "    with Image.open(image_file) as img:\n",
        "        array = np.asarray(img, np.float32).transpose([2, 0, 1]) / 255.0\n",
        "        tensor = torch.as_tensor(np.expand_dims(array, axis=0))  # rank 4\n",
        "    return tensor\n",
        "\n",
        "\n",
        "def sharpen_filter(image_file):\n",
        "    kernel = np.array([[-2, -2, -2], [-2, 32, -2], [-2, -2, -2]], np.float32) / 16.0  # convolution filter\n",
        "    with torch.no_grad():\n",
        "        # [out_ch, in_ch, .., ..] : channel wiseに計算\n",
        "        sharpen_k = torch.as_tensor(kernel.reshape(1, 1, 3, 3))\n",
        "\n",
        "        color = load_tensor(image_file)  # color image [1, 3, H, W]\n",
        "        # channel-wise conv(大事)　3x3 convなのでPadding=1を入れる\n",
        "        multiband = [F.conv2d(color[:, i:i + 1,:,:], sharpen_k, padding=1) for i in range(3)]\n",
        "        sharpened_image = torch.cat(multiband, dim=1)\n",
        "        torchvision.utils.save_image(sharpened_image, image_file)\n",
        "\n",
        "\n",
        "def sharpen_movie(video_folder, video_file, k, frame_rate):\n",
        "  decomposit_video(video_folder,video_file)\n",
        "\n",
        "  files = glob.glob(video_folder+'/*.png')\n",
        "  for ifile in files:\n",
        "    print(\"Now processing \",ifile)\n",
        "    sharpen_filter(ifile)\n",
        "\n",
        "  composit_video(video_folder, video_file, frame_rate)\n",
        "\n",
        "\n",
        "def colorize_video(source_video, output_video, render_factor):\n",
        "  print(source_video)\n",
        "  print(output_video)\n",
        "\n",
        "  if os.path.isfile(\"/content/DeOldify/video\"):\n",
        "    shutil.rmtree(\"/content/DeOldify/video\")\n",
        "\n",
        "  !mkdir -p '/content/DeOldify/video/source'\n",
        "\n",
        "  command1=\"cp -r \" + source_video + \" /content/DeOldify/video/source/video.mp4\"\n",
        "  subprocess.run(command1,shell=True)\n",
        "  print(command1)\n",
        "#  !cp -r str(source_video) /content/DeOldify/video/source/video.mp4\n",
        "  video_path = colorizer.colorize_from_file_name('/content/DeOldify/video/source/video.mp4', render_factor)\n",
        " \n",
        "  command2=\"cp -r /content/DeOldify/video/result/video.mp4 \" + output_video\n",
        "  subprocess.run(command2,shell=True)\n",
        "#  !cp -r /content/DeOldify/video/result/video.mp4 str(output_video)\n",
        "  print(command2)\n",
        "  if os.path.isfile(\"/content/DeOldify/video/result/video.mp4\"):\n",
        "    os.remove(\"/content/DeOldify/video/result/video.mp4\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pL23bEM24R4l"
      },
      "source": [
        "#◢ 画像のダウンロード"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7odvNQ3P0KAt",
        "cellView": "form",
        "outputId": "80afdbca-e4be-43d1-ca7f-b4ef96f1221e"
      },
      "source": [
        "#@title 割り当てられたGPUの確認\n",
        "# Check your current GPU\n",
        "# If you are lucky, you get 16GB VRAM. If you are not lucky, you get less. VRAM is important. The more VRAM, the higher the maximum resolution will go.\n",
        "\n",
        "# 16GB: Can handle 720p. 1080p will procude an out-of-memory error. \n",
        "# 8GB: Can handle 480p. 720p will produce an out-of-memory error.\n",
        "\n",
        "!nvidia-smi --query-gpu=gpu_name,driver_version,memory.total --format=csv"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "name, driver_version, memory.total [MiB]\n",
            "Tesla P100-PCIE-16GB, 460.32.03, 16280 MiB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-pMiFqHO0hpA",
        "cellView": "form",
        "outputId": "d6516332-168f-43a7-ee4d-f3d2d57ef7d3"
      },
      "source": [
        "#@title **Googleドライブの追加**\n",
        "# Connect Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "print('Google Drive connected.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Google Drive connected.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eaANNxvjMLUZ",
        "outputId": "4c2a693c-0fbe-4b34-f259-6f24819bc2e3"
      },
      "source": [
        "#@title ##**ビデオのダウンロード** { display-mode: \"form\" }\n",
        "#@markdown *ビデオへのリンク（YouTubeやTwitterなど）を入力するか、source_urlフィールドを空白にしてください（空白にした場合、コンピューターからビデオをアップロードするよう求められます）。*\n",
        "#@markdown *プロジェクト名は任意でOKです。一応最後にGoogle Driveにプロジェクト名で指定したディレクトリが作られて、途中経過も含めて全ての動画ファイルがコピーされます*\n",
        "\n",
        "import youtube_dl\n",
        "import cv2\n",
        "from IPython.display import clear_output\n",
        "\n",
        "%cd /content\n",
        "\n",
        "projectname = 'Miyazaki_Kiyoshiro' #@param {type:\"string\"}\n",
        "\n",
        "source_url = 'https://www.youtube.com/watch?v=IiAQpmP4W9Q' #@param {type:\"string\"}\n",
        "\n",
        "%cd /content\n",
        "! rm -f /content/*.mp4\n",
        "\n",
        "if source_url == '':\n",
        "  uploaded = files.upload()\n",
        "  for fn in uploaded.keys():\n",
        "    print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "        name=fn, length=len(uploaded[fn])))\n",
        "  os.rename(fn, fn.replace(\" \", \"\"))\n",
        "  fn = fn.replace(\" \", \"\")\n",
        "  file_name = \"downloaded_video.\" + fn.split(\".\")[-1]\n",
        "  !mv -f $fn $file_name\n",
        "\n",
        "else:\n",
        "  try:\n",
        "    ydl_opts = {\n",
        "        'format': 'bestvideo[ext=mp4]+bestaudio[ext=m4a]/mp4',\n",
        "        'outtmpl': 'downloaded_video.mp4',\n",
        "        }\n",
        "    with youtube_dl.YoutubeDL(ydl_opts) as ydl:\n",
        "      ydl.download([source_url])\n",
        "    file_name = 'downloaded_video.mp4'\n",
        "  \n",
        "  except BaseException:\n",
        "    !wget $source_url\n",
        "    fn = source_url.split('/')[-1]\n",
        "    os.rename(fn, fn.replace(\" \", \"\"))\n",
        "    fn = fn.replace(\" \", \"\")\n",
        "    file_name = \"downloaded_video.\" + fn.split(\".\")[-1]\n",
        "    !mv -f $fn $file_name\n",
        "\n",
        "!cp -r /content/downloaded_video.mp4 /content/video.mp4\n",
        "\n",
        "clear_output()\n",
        "\n",
        "fps_of_video = int(cv2.VideoCapture(file_name).get(cv2.CAP_PROP_FPS))\n",
        "frames_of_video = int(cv2.VideoCapture(file_name).get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "width_of_video = int(cv2.VideoCapture(file_name).get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "height_of_video = int(cv2.VideoCapture(file_name).get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "print (\"FPS of VIDEO: \",fps_of_video)\n",
        "print (\"Frames of VIDEO: \",frames_of_video)\n",
        "print (\"Width of VIDEO: \",width_of_video)\n",
        "print (\"Height of VIDEO: \",height_of_video)\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FPS of VIDEO:  15\n",
            "Frames of VIDEO:  936\n",
            "Width of VIDEO:  480\n",
            "Height of VIDEO:  360\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04nmb31hVZ44"
      },
      "source": [
        "#@title ##**ダウンロードした動画を表示** { display-mode: \"form\" }\n",
        "#@markdown *ビデオは横640ドットに拡大/縮小されて表示されます*\n",
        "import moviepy.editor as mpy\n",
        "\n",
        "what_next = 'play' #@param [\"play\", \"download\"]\n",
        "if what_next == \"play\":\n",
        "  display(mpy.ipython_display(\"/content/downloaded_video.mp4\", autoplay=1, maxduration=6000,width=640))\n",
        "else:\n",
        "  files.download('/content/downloaded_video.mp4')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ObdmOuzz13m"
      },
      "source": [
        "#@title ##**動画の調整** { display-mode: \"form\" }\n",
        "\n",
        "#@markdown *1分以上の動画をダウンロードすることはお勧めできません。また、タイトルに「スペース」や「ドット」が含まれている動画はアップロードしないでください。*\n",
        "#@markdown *実行中にエラーが発生した場合は、このブロックを再度実行します。*\n",
        "#@markdown *動画の長さを変更することができます。*\n",
        "\n",
        "#@markdown **動画の長さを変更する場合は、その開始時間と終了時間を指定して下さい。**\n",
        "target_start = '00:00:27' #@param {type:\"string\"}\n",
        "target_end = '00:00:42' #@param {type:\"string\"}\n",
        "\n",
        "\n",
        "if os.path.isfile(\"/content/cropped_video.mp4\"):\n",
        "    os.remove(\"/content/cropped_video.mp4\")\n",
        "\n",
        "!ffmpeg -i /content/downloaded_video.mp4  -ss $target_start -to $target_end /content/cropped_video.mp4\n",
        "\n",
        "if os.path.isfile(\"/content/video.mp4\"):\n",
        "    os.remove(\"/content/video.mp4\")\n",
        "\n",
        "!cp /content/cropped_video.mp4 /content/video.mp4\n",
        "\n",
        "#@markdown **モノクロ動画にAIで色を付ける場合は有効にしてください。**\n",
        "is_deoldify = True #@param {type:\"boolean\"}\n",
        "\n",
        "\n",
        "#@markdown **Deoldifyのレンダリングファクターを指定します。(お勧めは10～25）**\n",
        "render_factor = 13  #@param {type: \"slider\", min: 5, max: 44}\n",
        "\n",
        "#@markdown **アンシャープマスクを適用する場合は有効にして下さい。**\n",
        "is_unsharp = True #@param {type:\"boolean\"}\n",
        "\n",
        "\n",
        "#@markdown **DeepRemasterを有効にすると、低画質の動画からノイズなどを除去できます。**\n",
        "is_DeepRemaster = True #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown **GANを使って、動画の顔部分を書き換えます。大体はがっかりしますが、時々きれいに修正されることがあります**\n",
        "\n",
        "#@markdown **Microsoft Bringing-Old-Photos-Back-to-LifeまたはGFPGANを選択して、いずれかの手法で人物の精彩化を試みます。**\n",
        "which_FaceGAN = 'Microsoft' #@param [\"None\", \"GFPGAN\", \"Microsoft\"] {allow-input: true}\n",
        "\n",
        "clear_output()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IqUFrU1vMiXw"
      },
      "source": [
        "#@title ##**サイズ調整後の動画を表示（修復対象）** { display-mode: \"form\" }\n",
        "\n",
        "what_next = 'play' #@param [\"play\", \"download\"]\n",
        "if what_next == \"play\":\n",
        "#  display(mpy.ipython_display(\"/content/video.mp4\", height=400, autoplay=1, maxduration=600))\n",
        "  display(mpy.ipython_display(\"/content/video.mp4\", autoplay=1, maxduration=600, width=640))\n",
        "else:\n",
        "  files.download('/content/video.mp4')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ilupJKa63God",
        "outputId": "59bd1de3-f45d-4f5f-b376-aaa30007de02",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%cd /content\n",
        "!git clone https://github.com/JoeyBallentine/Video-Inference.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'Video-Inference'...\n",
            "remote: Enumerating objects: 131, done.\u001b[K\n",
            "remote: Counting objects: 100% (131/131), done.\u001b[K\n",
            "remote: Compressing objects: 100% (121/121), done.\u001b[K\n",
            "remote: Total 131 (delta 53), reused 78 (delta 5), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (131/131), 20.40 MiB | 38.32 MiB/s, done.\n",
            "Resolving deltas: 100% (53/53), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8jS-DPT3iq1",
        "outputId": "ac06d6c4-1908-4d2a-9af1-c0fde2dd347e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%cd /content/Video-Inference/models/\n",
        "!wget https://drive.google.com/file/d/13FPxKE6q7tuRrfhTE7GB040jBeURBj58/view\n",
        "!wget https://drive.google.com/file/d/1ie1F7wJcO4mhNWK8nPX7F0LgOoPzCwEu/view\n",
        "!wget https://u.pcloud.link/publink/show?code=XZeXKLXZdqXM0uCIGvH7IFyg0sSwC7dl2y2X\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Video-Inference/models\n",
            "--2021-10-18 14:51:42--  https://drive.google.com/file/d/13FPxKE6q7tuRrfhTE7GB040jBeURBj58/view\n",
            "Resolving drive.google.com (drive.google.com)... 173.194.218.101, 173.194.218.139, 173.194.218.138, ...\n",
            "Connecting to drive.google.com (drive.google.com)|173.194.218.101|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘view’\n",
            "\n",
            "view                    [ <=>                ]  64.24K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2021-10-18 14:51:42 (18.0 MB/s) - ‘view’ saved [65783]\n",
            "\n",
            "--2021-10-18 14:51:42--  https://drive.google.com/file/d/1ie1F7wJcO4mhNWK8nPX7F0LgOoPzCwEu/view\n",
            "Resolving drive.google.com (drive.google.com)... 173.194.218.100, 173.194.218.101, 173.194.218.139, ...\n",
            "Connecting to drive.google.com (drive.google.com)|173.194.218.100|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘view.1’\n",
            "\n",
            "view.1                  [ <=>                ]  64.24K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2021-10-18 14:51:42 (12.1 MB/s) - ‘view.1’ saved [65783]\n",
            "\n",
            "--2021-10-18 14:51:43--  https://u.pcloud.link/publink/show?code=XZeXKLXZdqXM0uCIGvH7IFyg0sSwC7dl2y2X\n",
            "Resolving u.pcloud.link (u.pcloud.link)... 74.120.8.103, 74.120.8.102, 74.120.10.6, ...\n",
            "Connecting to u.pcloud.link (u.pcloud.link)|74.120.8.103|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 45616 (45K) [text/html]\n",
            "Saving to: ‘show?code=XZeXKLXZdqXM0uCIGvH7IFyg0sSwC7dl2y2X’\n",
            "\n",
            "show?code=XZeXKLXZd 100%[===================>]  44.55K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2021-10-18 14:51:43 (1.22 MB/s) - ‘show?code=XZeXKLXZdqXM0uCIGvH7IFyg0sSwC7dl2y2X’ saved [45616/45616]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uj9MorJW7FN8",
        "outputId": "687edb3d-7b6a-4097-f8ae-79142de02c41",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%cd /content/Video-Inference/\n",
        "!python run.py ./models/TecoGAN_BI_iter500000.pth --input \"./input/video.mp4\" --output \"./output/output_video.mp4\""
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Video-Inference\n",
            "N/A% (0 of 936) |                         | Elapsed Time: 0:00:00 ETA:  --:--:--/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
            "100% (936 of 936) |#######################| Elapsed Time: 0:03:27 Time:  0:03:27\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YDpU1e0WCbvM",
        "cellView": "form"
      },
      "source": [
        "#@title  ##**動画にアンシャープマスクをかける**\n",
        "if is_unsharp == True:\n",
        "  sharpen_movie(\"/content/datas\", \"/content/video.mp4\", 1.0, fps_of_video)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TXnweFAqiLuF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d838713-8f66-478c-a6d1-5b25bc00682b"
      },
      "source": [
        "#@title ##**動画をシーンごとに分割する** { display-mode: \"form\" }\n",
        "\n",
        "splitted_folder=\"/content/movies\"\n",
        "source_video=\"/content/video.mp4\"\n",
        "if os.path.isdir(splitted_folder):\n",
        "    shutil.rmtree(splitted_folder)\n",
        "os.mkdir(splitted_folder)\n",
        "\n",
        "#シーンごとに動画を分割する\n",
        "split_command=\"scenedetect -i \" + source_video + \" -o \" + splitted_folder + \" detect-content -t 27 list-scenes save-images split-video\"\n",
        "subprocess.run(split_command,shell=True)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CompletedProcess(args='scenedetect -i /content/video.mp4 -o /content/movies detect-content -t 27 list-scenes save-images split-video', returncode=0)"
            ]
          },
          "metadata": {},
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-f1MDliBGGGL"
      },
      "source": [
        "# #◢ モノクロ動画に色を付ける"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37yAH_olbROZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "cellView": "form",
        "outputId": "92ef5e75-8437-4cbf-9597-df9c35d661f9"
      },
      "source": [
        "#@title Deoldifyによるモノクロ動画のカラー化\n",
        "if is_deoldify == True:\n",
        "\n",
        "  %cd /content/DeOldify\n",
        "\n",
        "  if os.path.isfile(\"/content/DeOldify/video\"):\n",
        "    shutil.rmtree(\"/content/DeOldify/video\")\n",
        "\n",
        "  !mkdir -p '/content/DeOldify/video/source'\n",
        "\n",
        "  !cp -r /content/video.mp4 /content/DeOldify/video/source/video.mp4\n",
        "  video_path = colorizer.colorize_from_file_name('/content/DeOldify/video/source/video.mp4', render_factor)\n",
        "  !cp -r /content/DeOldify/video/result/video.mp4 /content/colorized_video.mp4\n",
        "  !cp -r /content/colorized_video.mp4 /content/video.mp4\n",
        "  if os.path.isfile(\"/content/DeOldify/video/result/video.mp4\"):\n",
        "    os.remove(\"/content/DeOldify/video/result/video.mp4\")\n",
        "\n",
        "\n",
        "#colorize_video('/content/video.mp4', '/content/colorized_video.mp4', render_factor)\n",
        "#!cp /content/colorized_video /content/video.mp4"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/DeOldify\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='360' class='' max='360' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      100.00% [360/360 00:31<00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Video created here: video/result/video.mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FakQk0wBE5GS"
      },
      "source": [
        "# #◢ ノイズ除去(Deep Remaster)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzu_lk9DKbTO"
      },
      "source": [
        "#@title ##**Remove frame noise** { display-mode: \"form\" }\n",
        "%cd /content/DeepRemaster\n",
        "command = \"python remaster.py --input /content/video.mp4 --disable_colorization --gpu --mindim \" + str(height_of_video)\n",
        "\n",
        "subprocess.run(command,shell=True)\n",
        "#!python remaster.py --input /content/video.mp4 --disable_colorization --gpu --mindim 1080\n",
        "#!python remaster.py --input /content/video.mp4 --disable_colorization --gpu\n",
        "#clear_output()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3tKlt3_S9DgG"
      },
      "source": [
        "#◢ Microsoft Bringing-Old-Photos-Back-to-Lifeによる画像修正"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qTmlNEoU-END"
      },
      "source": [
        "#@title 動画ファイルを画像ファイルに分解\n",
        "# ffmpeg extract - Generating individual frame PNGs from the source file.\n",
        "\n",
        "if which_FaceGAN == \"Microsoft\":\n",
        "\n",
        "  %cd /content/photo_restoration\n",
        "\n",
        "  FRAME_INPUT_DIR = \"/content/photo_restoration/input_frames\"\n",
        "  FRAME_OUTPUT_DIR = \"/content/photo_restoration/output_frames\"\n",
        "  INPUT_FILEPATH = \"/content/video.mp4\"\n",
        "\n",
        "  if os.path.isfile(FRAME_INPUT_DIR):\n",
        "    shutil.retree(FRAME_INPUT_DIR)\n",
        "\n",
        "  %shell mkdir -p '{FRAME_INPUT_DIR}'\n",
        "\n",
        "  %shell ffmpeg -i '{INPUT_FILEPATH}' '{FRAME_INPUT_DIR}/%05d.png'\n",
        "\n",
        "  if os.path.isfile(FRAME_OUTPUT_DIR):\n",
        "    shutil.retree(FRAME_OUTPUT_DIR)\n",
        "  \n",
        "  %shell mkdir -p '{FRAME_OUTPUT_DIR}'\n",
        "\n",
        "\n",
        "  png_generated_count_command_result = %shell ls '{FRAME_INPUT_DIR}' | wc -l\n",
        "  from IPython.display import clear_output\n",
        "\n",
        "  pngs_generated_count = int(png_generated_count_command_result.output.strip())\n",
        "\n",
        "\n",
        "  #print(f\"Input FPS: {fps}\")\n",
        "  print(f\"{pngs_generated_count} frame PNGs generated.\")\n",
        "\n",
        "  # Checking if PNG do have alpha\n",
        "  import subprocess as sp\n",
        "  %cd {FRAME_INPUT_DIR}\n",
        "  channels = sp.getoutput('identify -format %[channels] 00001.png')\n",
        "  print (f\"{channels} detected\")\n",
        "\n",
        "  # Removing alpha if detected\n",
        "  if \"a\" in channels:\n",
        "    print(\"Alpha detected and will be removed.\")\n",
        "    print(sp.getoutput('find . -name \"*.png\" -exec convert \"{}\" -alpha off PNG24:\"{}\" \\;'))\n",
        "\n",
        "  %cd /content/photo_restoration\n",
        "  input_folder = FRAME_INPUT_DIR\n",
        "  output_folder = FRAME_OUTPUT_DIR\n",
        "\n",
        "  !rm -rf /content/photo_restoration/output_frames/*\n",
        "\n",
        "  print (input_folder)\n",
        "  print (output_folder)\n",
        "\n",
        "  import os\n",
        "  basepath = os.getcwd()\n",
        "  #input_path = os.path.join(basepath, input_folder)\n",
        "  #output_path = os.path.join(basepath, output_folder)\n",
        "  #os.mkdir(output_path)\n",
        "  #!rm -rf output_folder\n",
        "  #os.mkdir(output_folder)\n",
        "\n",
        "  !python run.py --input_folder /content/photo_restoration/input_frames --output_folder /content/photo_restoration/output_frames --GPU 0\n",
        "\n",
        "#create video\n",
        "\n",
        "  %cd /content/photo_restoration/output_frames/final_output\n",
        "  !ffmpeg  -pattern_type glob -i '*.png' -c:v h264_nvenc -pix_fmt yuv420p /content/beautified_video.mp4\n",
        "  !rm -f /content/video.mp4\n",
        "  !cp /content/beautified_video.mp4 /content/video.mp4\n",
        "  clear_output()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aGrd5Y8nmCzD"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "smSeEdA4Mv5X"
      },
      "source": [
        "#◢ GFPGANによる顔画像の修復"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OzlCT4FRGrGt"
      },
      "source": [
        "#@title ##**GFPGANを使って動画ファイル中の顔画像を修復** { display-mode: \"form\" }\n",
        "\n",
        "if which_FaceGAN == \"GFPGAN\":\n",
        "\n",
        "  upload_folder = \"/content/GFPGAN/inputs/upload\"\n",
        "  if os.path.isdir(upload_folder):\n",
        "    shutil.rmtree(upload_folder)\n",
        "\n",
        "  os.mkdir(upload_folder)\n",
        "\n",
        "  %cd /content/GFPGAN/inputs/upload\n",
        "\n",
        "  !ffmpeg -i /content/video.mp4 %09d.png\n",
        "\n",
        "# Now we use the GFPGAN to restore the above low-quality images\n",
        "# We use [Real-ESRGAN](https://github.com/xinntao/Real-ESRGAN) for enhancing the background (non-face) regions\n",
        "\n",
        "  %cd /content/GFPGAN\n",
        "  !rm -rf results\n",
        "  !python inference_gfpgan.py --upscale 2 --test_path inputs/upload --save_root results --model_path experiments/pretrained_models/GFPGANCleanv1-NoCE-C2.pth --bg_upsampler realesrgan\n",
        "\n",
        "  if os.path.isfile(\"/content/restored_video.mp4\") :\n",
        "    !rm -f /content/restored_video.mp4\n",
        "\n",
        "  !ffmpeg -f image2 -framerate 30 -i /content/GFPGAN/results/restored_imgs/%09d.png -c:v h264_nvenc -preset slow -qp 18 -pix_fmt yuv420p /content/beautified_video.mp4\n",
        "  !rm -f /content/video.mp4\n",
        "  !cp /content/beautified_video.mp4 /content/video.mp4\n",
        "\n",
        "  clear_output()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x1Yy74PQnWUE"
      },
      "source": [
        "#◢ 最終処理"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Cj0Kxnzi_ah",
        "cellView": "form",
        "outputId": "bde343b1-f95c-42cb-a554-8c3cc1621188"
      },
      "source": [
        "#@title ファイルのバックアップ\n",
        "\n",
        "ProjectDir=\"/content/drive/MyDrive/Movie/\"+str(projectname)\n",
        "print(\"ProjectDir\")\n",
        "\n",
        "if os.path.isfile(ProjectDir):\n",
        "    shutil.rmtree(ProjectDir)\n",
        "\n",
        "os.mkdir(ProjectDir)\n",
        "os.chdir(ProjectDir)\n",
        "!mv /content/*.mp4 ."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ProjectDir\n"
          ]
        }
      ]
    }
  ]
}